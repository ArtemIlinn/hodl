{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "–ü–∞—Ä—Å–∏–Ω–≥ –°–±–µ—Ä–∞"
      ],
      "metadata": {
        "id": "OOcJTWa2rsMg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd\n",
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "base_url = \"https://smart-lab.ru/forum/SBER/page\"\n",
        "page_number = 10944\n",
        "\n",
        "id = 0\n",
        "\n",
        "sber_df = pd.DataFrame(columns=[\"id\", \"username\", \"post\", \"ticker\"])\n",
        "\n",
        "for i in range(15):\n",
        "  url = base_url + str(page_number)\n",
        "  page_number -= 1\n",
        "  # Send a GET request to the URL\n",
        "  response = requests.get(url)\n",
        "\n",
        "\n",
        "  # Check if the request was successful\n",
        "  if response.status_code == 200:\n",
        "      # Parse the HTML content\n",
        "      soup = BeautifulSoup(response.content, \"html.parser\")\n",
        "\n",
        "      comment_elements = soup.find_all('li', attrs={\"class\": \"cm_wrap\", \"data-type\":\"comment\"})\n",
        "\n",
        "\n",
        "      for comment in comment_elements:\n",
        "          comment = str(comment)\n",
        "\n",
        "          comment_soup = BeautifulSoup(comment, \"html.parser\")\n",
        "          username = comment_soup.find('a', class_='a_name').get_text(strip=True)\n",
        "          post = comment_soup.find('div', class_='text').get_text(strip=True)\n",
        "\n",
        "          # # Print the extracted data\n",
        "          # print(\"Username:\", username)\n",
        "          # print(\"Post:\", post)\n",
        "          # print()\n",
        "          # # print(comment)\n",
        "          # # print()\n",
        "          new_row = pd.DataFrame({\n",
        "              \"id\": id,\n",
        "              \"username\": username,\n",
        "              \"post\": post,\n",
        "              \"ticker\": [\"SBER\"]\n",
        "          })\n",
        "          id+=1\n",
        "\n",
        "          sber_df = pd.concat([sber_df, new_row], ignore_index=True)\n",
        "\n",
        "  else:\n",
        "      print(\"Failed to retrieve the webpage\")\n",
        "\n",
        "print(sber_df)\n",
        "\n",
        "sber_df.to_csv('/content/drive/MyDrive/HODL Project/sber_df.csv', index=False)"
      ],
      "metadata": {
        "id": "6xAQ_pafSrOo",
        "outputId": "f9242b38-06da-42e3-ae0d-ad0f012e319f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "      id        username                                               post  \\\n",
            "0      0  –ü—É—Ç–µ—à–µ—Å—Ç–≤–µ–Ω–Ω–∏–∫  –ù–µ –ø–æ—Ä–∞ –ª–∏ —Ö–æ—Ä–æ—à–µ–Ω—å–∫–æ —É–ø–∞—Å—Ç—å?1-–°–º–æ—Ç—Ä–∏–º –≥–µ–ø—ã. 1...   \n",
            "1      1   –ò–≥–æ—Ä—å –†–æ–¥–∏—á–µ–≤  –ü—Ä–æ–º–µ–∂—É—Ç–æ—á–Ω—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç –≤–æ–ª–Ω–æ–≤–∞–ª –±—ã –≤ –æ–¥–Ω–æ–º –ø—Ä...   \n",
            "2      2   –ò–≥–æ—Ä—å –†–æ–¥–∏—á–µ–≤  –ò–≥–æ—Ä—å –†–æ–¥–∏—á–µ–≤, –ö–∞–∫—É—é —Ü–µ–Ω—É –ø—Ä–æ–≥–Ω–æ–∑–∏—Ä—É–µ—Ç–µ –Ω–∞ –∫–æ–Ω...   \n",
            "3      3   –ò–≥–æ—Ä—å –†–æ–¥–∏—á–µ–≤  –ò–≥–æ—Ä—å –†–æ–¥–∏—á–µ–≤, –ö–∞–∫—É—é —Ü–µ–Ω—É –ø—Ä–æ–≥–Ω–æ–∑–∏—Ä—É–µ—Ç–µ –Ω–∞ –∫–æ–Ω...   \n",
            "4      4  –ê–ª–µ–∫—Å–µ–π –ú–∞–º–∞–µ–≤          —Å–∞–º–æ–µ –≤–µ—Å–µ–ª–æ–µ —á—Ç–æ –Ω–∏–∫—Ç–æ –Ω–µ –≤–∫—É—Ä–∏–ª —Ç–µ–º—É)))   \n",
            "..   ...             ...                                                ...   \n",
            "370  370            Chef  Chef, –∞—Ç–ª–∏—á–Ω–∞, –±—É—à –º–∞–∏–º –ø–∏—Ä–∏–≤–æ—Ç—á–∏–∫–æ–º‚Ä¶ –Ω–∞–∑–Ω–∞—á–∞—é...   \n",
            "371  371      –ö–æ–Ω—Å—Ç–∞–Ω—Ç–∏–Ω              –±–∞–±–∫–∏ —Å —Ñ–æ–Ω–¥—ã –æ–ø—è—Ç—å –Ω–∞ –≤–∞–ª—é—Ç—É –≤—ã–Ω—É–ª–∏)   \n",
            "372  372      –ö–æ–Ω—Å—Ç–∞–Ω—Ç–∏–Ω  –ö–æ–Ω—Å—Ç–∞–Ω—Ç–∏–Ω, —Ç—É—Ç –∏–ª–∏ –∏—Ä–∞–Ω—Å–∫–∏–π —Å—Ü–µ–Ω–∞—Ä–∏–π –∏–ª–∏ —Å–±–µ—Ä...   \n",
            "373  373      –ö–æ–Ω—Å—Ç–∞–Ω—Ç–∏–Ω  –ö–æ–Ω—Å—Ç–∞–Ω—Ç–∏–Ω, –≥–æ–ª–æ—Å–æ–≤–∞—Ç—å –Ω–∞–¥–æ –±—ã–ª–æ —Ä–∞–Ω—å—à–µ–≤ 2000‚úî...   \n",
            "374  374    Anton Palyhc  Anton Palyhc, —è —á–µ—Ç –≤ –≥–æ–ª–æ—Å —Å –Ω–∞—à–µ–≥–æ —Ä—ã–Ω–∫–∞ —Å —Ç...   \n",
            "\n",
            "    ticker  \n",
            "0     SBER  \n",
            "1     SBER  \n",
            "2     SBER  \n",
            "3     SBER  \n",
            "4     SBER  \n",
            "..     ...  \n",
            "370   SBER  \n",
            "371   SBER  \n",
            "372   SBER  \n",
            "373   SBER  \n",
            "374   SBER  \n",
            "\n",
            "[375 rows x 4 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "–ü–∞—Ä—Å–∏–Ω–≥ –ì–∞–∑–ø—Ä–æ–º"
      ],
      "metadata": {
        "id": "QW-aDbz5vfLV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd\n",
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "base_url = \"https://smart-lab.ru/forum/GAZP/page\"\n",
        "page_number = 3048\n",
        "\n",
        "id = 0\n",
        "gazprom_df = pd.DataFrame(columns=[\"id\", \"username\", \"post\", \"ticker\"])\n",
        "\n",
        "for i in range(15):\n",
        "  url = base_url + str(page_number)\n",
        "  page_number -= 1\n",
        "  # Send a GET request to the URL\n",
        "  response = requests.get(url)\n",
        "\n",
        "\n",
        "  # Check if the request was successful\n",
        "  if response.status_code == 200:\n",
        "      # Parse the HTML content\n",
        "      soup = BeautifulSoup(response.content, \"html.parser\")\n",
        "\n",
        "      comment_elements = soup.find_all('li', attrs={\"class\": \"cm_wrap\", \"data-type\":\"comment\"})\n",
        "\n",
        "\n",
        "      for comment in comment_elements:\n",
        "          comment = str(comment)\n",
        "\n",
        "          comment_soup = BeautifulSoup(comment, \"html.parser\")\n",
        "          username = comment_soup.find('a', class_='a_name').get_text(strip=True)\n",
        "          post = comment_soup.find('div', class_='text').get_text(strip=True)\n",
        "\n",
        "          # # Print the extracted data\n",
        "          # print(\"Username:\", username)\n",
        "          # print(\"Post:\", post)\n",
        "          # print()\n",
        "          # # print(comment)\n",
        "          # # print()\n",
        "          new_row = pd.DataFrame({\n",
        "              \"id\": id,\n",
        "              \"username\": username,\n",
        "              \"post\": post,\n",
        "              \"ticker\": [\"GAZP\"]\n",
        "          })\n",
        "          id+=1\n",
        "\n",
        "          gazprom_df = pd.concat([gazprom_df, new_row], ignore_index=True)\n",
        "\n",
        "  else:\n",
        "      print(\"Failed to retrieve the webpage\")\n",
        "\n",
        "print(gazprom_df)\n",
        "\n",
        "gazprom_df.to_csv('/content/drive/MyDrive/HODL Project/gazprom_df.csv', index=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9KuLYgwXvq4e",
        "outputId": "b44722d7-b131-4072-b337-7537b404c18c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "      id          username                                               post  \\\n",
            "0      0     –°–µ—Ä–≥–µ–π –ê–Ω–æ–Ω–∏–º  1. –ö–æ–º–ø–∞–Ω–∏—è —É–∂–∞—Å–Ω–æ (–ø–æ–¥—á—ë—Ä–∫–∏–≤–∞—é, —É–∂–∞—Å–Ω–æ) –Ω–µ–¥–æ–æ...   \n",
            "1      1        –ö–æ–Ω—Å—Ç–∞–Ω—Ç–∏–Ω  –ö–æ–Ω—Å—Ç–∞–Ω—Ç–∏–Ω, —Ç–∞—Ä—å—Ç–µ, –∫—Ç–æ –≤–∞–º –Ω–µ –¥–∞—ë—Ç —Ç–æ? –î–ª—è —á–µ...   \n",
            "2      2        –ö–æ–Ω—Å—Ç–∞–Ω—Ç–∏–Ω  –ö–æ–Ω—Å—Ç–∞–Ω—Ç–∏–Ω, —Ç–∞—Ä—å—Ç–µ, –∫—Ç–æ –≤–∞–º –Ω–µ –¥–∞—ë—Ç —Ç–æ? –î–ª—è —á–µ...   \n",
            "3      3            Bablos  1. –ö–æ–º–ø–∞–Ω–∏—è —É–∂–∞—Å–Ω–æ (–ø–æ–¥—á—ë—Ä–∫–∏–≤–∞—é, —É–∂–∞—Å–Ω–æ) –Ω–µ–¥–æ–æ...   \n",
            "4      4         UshiSlona  –Ω–∞ dohod.ru –æ–∂–∏–¥–∞—é—Ç, —á—Ç–æ –ì–ü –≤—ã–¥–∞—Å—Ç –ø–æ–ª—É–≥–æ–¥–æ–≤—ã–µ...   \n",
            "..   ...               ...                                                ...   \n",
            "370  370  –ê–ª–µ–∫—Å–∞–Ω–¥—Ä –í–ª–∞—Å–æ–≤  –ê–∫—Ü–∏—è —Å—Ç–æ–∏—Ç 1.8 –¥–æ–ª–ª–∞—Ä–∞. –†–∞–Ω–µ–µ –∏ –ø–æ 10 –±—Ä–∞–ª–∏. ...   \n",
            "371  371  –ê–Ω–¥—Ä–µ–π –°–µ—Ä–≥–µ–µ–≤–∏—á  –ê–Ω–¥—Ä–µ–π –°–µ—Ä–≥–µ–µ–≤–∏—á, –∞ –º–Ω–µ –∫–∞–∂–µ—Ç—Å—è —á—Ç–æ —É –º–µ–Ω—è 1 —Å...   \n",
            "372  372  –ê–ª–µ–∫—Å–∞–Ω–¥—Ä –í–ª–∞—Å–æ–≤  –ê–Ω–¥—Ä–µ–π –°–µ—Ä–≥–µ–µ–≤–∏—á, –ú–ù–ï –ö–ê–ñ–ö–¢–°–Ø –ß–¢–û –Ø –¢–£ –û–î–ò–ù –í ...   \n",
            "373  373  –ê–ª–µ–∫—Å–∞–Ω–¥—Ä –í–ª–∞—Å–æ–≤  –ê–ª–µ–∫—Å–∞–Ω–¥—Ä –í–ª–∞—Å–æ–≤, –ù—É —Ö–æ—Ä–æ—à–æ, –µ—Å–ª–∏ —Ç—ã —Å–µ–≥–æ–¥–Ω—è –ø...   \n",
            "374  374  –ê–Ω–¥—Ä–µ–π –°–µ—Ä–≥–µ–µ–≤–∏—á  –ê–ª–µ–∫—Å–∞–Ω–¥—Ä –í–ª–∞—Å–æ–≤, –ù—É —Ö–æ—Ä–æ—à–æ, –µ—Å–ª–∏ —Ç—ã —Å–µ–≥–æ–¥–Ω—è –ø...   \n",
            "\n",
            "    ticker  \n",
            "0     GAZP  \n",
            "1     GAZP  \n",
            "2     GAZP  \n",
            "3     GAZP  \n",
            "4     GAZP  \n",
            "..     ...  \n",
            "370   GAZP  \n",
            "371   GAZP  \n",
            "372   GAZP  \n",
            "373   GAZP  \n",
            "374   GAZP  \n",
            "\n",
            "[375 rows x 4 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "–ü–∞—Ä—Å–∏–Ω–≥ –Ø–Ω–¥–µ–∫—Å"
      ],
      "metadata": {
        "id": "J_EacTqpwkq_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd\n",
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "base_url = \"https://smart-lab.ru/forum/YNDX/page\"\n",
        "page_number = 430\n",
        "\n",
        "id = 0\n",
        "yandex_df = pd.DataFrame(columns=[\"id\", \"username\", \"post\", \"ticker\"])\n",
        "\n",
        "for i in range(15):\n",
        "  url = base_url + str(page_number)\n",
        "  page_number -= 1\n",
        "  # Send a GET request to the URL\n",
        "  response = requests.get(url)\n",
        "\n",
        "\n",
        "  # Check if the request was successful\n",
        "  if response.status_code == 200:\n",
        "      # Parse the HTML content\n",
        "      soup = BeautifulSoup(response.content, \"html.parser\")\n",
        "\n",
        "      comment_elements = soup.find_all('li', attrs={\"class\": \"cm_wrap\", \"data-type\":\"comment\"})\n",
        "\n",
        "\n",
        "      for comment in comment_elements:\n",
        "          comment = str(comment)\n",
        "\n",
        "          comment_soup = BeautifulSoup(comment, \"html.parser\")\n",
        "          username = comment_soup.find('a', class_='a_name').get_text(strip=True)\n",
        "          post = comment_soup.find('div', class_='text').get_text(strip=True)\n",
        "\n",
        "          # # Print the extracted data\n",
        "          # print(\"Username:\", username)\n",
        "          # print(\"Post:\", post)\n",
        "          # print()\n",
        "          # # print(comment)\n",
        "          # # print()\n",
        "\n",
        "          new_row = pd.DataFrame({\n",
        "              \"id\": id,\n",
        "              \"username\": username,\n",
        "              \"post\": post,\n",
        "              \"ticker\": [\"YNDX\"]\n",
        "          })\n",
        "          id+=1\n",
        "\n",
        "          yandex_df = pd.concat([yandex_df, new_row], ignore_index=True)\n",
        "\n",
        "  else:\n",
        "      print(\"Failed to retrieve the webpage\")\n",
        "\n",
        "print(yandex_df)\n",
        "\n",
        "yandex_df.to_csv('/content/drive/MyDrive/HODL Project/yandex_df.csv', index=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d0NEHKRiwm_E",
        "outputId": "46efded0-69f2-41db-90c0-432a9a8568ea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "      id              username  \\\n",
            "0      0  Territory of Trading   \n",
            "1      1    –ê–ª–µ–∫—Å–∞–Ω–¥—Ä –°–µ—Ä–µ–∂–∫–∏–Ω   \n",
            "2      2             –î–º–∏—Ç—Ä–∏–π –ú   \n",
            "3      3            Nordstream   \n",
            "4      4                   R B   \n",
            "..   ...                   ...   \n",
            "370  370      –ê–ª–µ–∫—Å–∞–Ω–¥—Ä –û—Å–∏–ø–æ–≤   \n",
            "371  371            –†–æ–º–∞–Ω –ñ–º–∞–∫   \n",
            "372  372               –î–º–∏—Ç—Ä–∏–π   \n",
            "373  373      –°—Ç–∞–Ω–∏—Å–ª–∞–≤ –®–≤–µ—Ü–æ–≤   \n",
            "374  374        –ù–∏–∫–æ–ª–∞–π –ò–≤–∞–Ω–æ–≤   \n",
            "\n",
            "                                                  post ticker  \n",
            "0    ‚úÖYandex–Ø—Ä—á–µ –ø–æ–¥—Ç–≤–µ—Ä–∂–¥–∞–µ—Ç—Å—è –∑–∞–≤–µ—Ä—à–µ–Ω–∏–µ –∫–æ—Ä—Ä–µ–∫—Ü–∏...   YNDX  \n",
            "1    –ì–µ–Ω–¥–∏—Ä–µ–∫—Ç–æ—Ä—É –∫–æ–º–ø–∞–Ω–∏–∏ \"–Ø–Ω–¥–µ–∫—Å\" –≥—Ä–æ–∑–∏—Ç —à—Ç—Ä–∞—Ñ–ê–¥–º...   YNDX  \n",
            "2                                      –î–æ—Ä–æ–≥–∞ –Ω–∞ 2100.   YNDX  \n",
            "3    –Ø–Ω–¥–µ–∫—Å –∑–∞–ø—É—Å—Ç–∏–ª B2B-—Å–µ—Ä–≤–∏—Å –Ø–Ω–¥–µ–∫—Å –ö–æ–º–∞–Ω–¥–∏—Ä–æ–≤–∫–∏...   YNDX  \n",
            "4    –ü—É—Ç–∏–Ω –Ω–∞–∑–≤–∞–ª –æ–±–Ω–∞–¥–µ–∂–∏–≤–∞—é—â–∏–º–∏ —ç–∫–æ–Ω–æ–º–∏—á–µ—Å–∫–∏–µ –ø–æ–∫...   YNDX  \n",
            "..                                                 ...    ...  \n",
            "370  –Ø–ù–î–ï–ö–°. –í–´–•–û–î –ò–ó –¢–†–ï–£–ì–û–õ–¨–ù–ò–ö–ê –í–í–ï–†–•. –†–ê–ó–ë–û–†–ï—â–µ...   YNDX  \n",
            "371  –Ø–Ω–¥–µ–∫—Å —Ä–∞—Å–∫—Ä—ã–ª —Å—É–º–º—É —Å–¥–µ–ª–∫–∏ –æ—Ç –ø—Ä–æ–¥–∞–∂–∏ –î–∑–µ–Ω–∞ V...   YNDX  \n",
            "372                                                  .   YNDX  \n",
            "373  \"–Ø–Ω–¥–µ–∫—Å\" –Ω–∞ \"–º–∞—Ä–∫–µ—Ç–µ\" - –∫—Ç–æ –∫—É–ø–∏—Ç –∫–æ–Ω—Ç—Ä–æ–ª—å –≤ —Ä...   YNDX  \n",
            "374  –ù–∏–∫–æ–ª–∞–π –ò–≤–∞–Ω–æ–≤,‚Ä¶ –ü—Ä–∏—á–∏–Ω–∞ +165 –ú–ª—Ä–¥. —Ä—É–± –≤ –ø—Ä–æ–¥...   YNDX  \n",
            "\n",
            "[375 rows x 4 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "–ü–∞—Ä—Å–∏–Ω–≥ –ú–∞–≥–Ω–∏—Ç"
      ],
      "metadata": {
        "id": "qKNyQ2syxD-2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd\n",
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "base_url = \"https://smart-lab.ru/forum/MGNT/page\"\n",
        "page_number = 648\n",
        "\n",
        "id = 0\n",
        "magnit_df = pd.DataFrame(columns=[\"id\", \"username\", \"post\", \"ticker\"])\n",
        "\n",
        "for i in range(15):\n",
        "  url = base_url + str(page_number)\n",
        "  page_number -= 1\n",
        "  # Send a GET request to the URL\n",
        "  response = requests.get(url)\n",
        "\n",
        "\n",
        "  # Check if the request was successful\n",
        "  if response.status_code == 200:\n",
        "      # Parse the HTML content\n",
        "      soup = BeautifulSoup(response.content, \"html.parser\")\n",
        "\n",
        "      comment_elements = soup.find_all('li', attrs={\"class\": \"cm_wrap\", \"data-type\":\"comment\"})\n",
        "\n",
        "\n",
        "      for comment in comment_elements:\n",
        "          comment = str(comment)\n",
        "\n",
        "          comment_soup = BeautifulSoup(comment, \"html.parser\")\n",
        "          username = comment_soup.find('a', class_='a_name').get_text(strip=True)\n",
        "          post = comment_soup.find('div', class_='text').get_text(strip=True)\n",
        "\n",
        "          new_row = pd.DataFrame({\n",
        "              \"id\": id,\n",
        "              \"username\": username,\n",
        "              \"post\": post,\n",
        "              \"ticker\": [\"MGNT\"]\n",
        "          })\n",
        "          id+=1\n",
        "\n",
        "          magnit_df = pd.concat([magnit_df, new_row], ignore_index=True)\n",
        "\n",
        "  else:\n",
        "      print(\"Failed to retrieve the webpage\")\n",
        "\n",
        "print(magnit_df)\n",
        "\n",
        "magnit_df.to_csv('/content/drive/MyDrive/HODL Project/magnit_df.csv', index=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aB3b9X9gxFt6",
        "outputId": "c9ec1413-546a-41da-ad0f-2aab7e464b97"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "      id           username  \\\n",
            "0      0     –ö–∞—Ä–∏–º –¢–∞–∫—Ç—É—Ä–æ–≤   \n",
            "1      1           Sergey Z   \n",
            "2      2               znak   \n",
            "3      3  –í–ª–∞–¥–∏–º–∏—Ä –õ–∏—Ç–≤–∏–Ω–æ–≤   \n",
            "4      4            –†–æ–º–∞–Ω–ü.   \n",
            "..   ...                ...   \n",
            "370  370                Max   \n",
            "371  371  –ö–æ–Ω—Å—Ç–∞–Ω—Ç–∏–Ω –ö–æ–±–ª–æ–≤   \n",
            "372  372      Heinrich Baur   \n",
            "373  373  –ö–æ–Ω—Å—Ç–∞–Ω—Ç–∏–Ω –ö–æ–±–ª–æ–≤   \n",
            "374  374                Max   \n",
            "\n",
            "                                                  post ticker  \n",
            "0    ü•¶ –ü—Ä–æ–¥—É–∫—Ç–æ–≤—ã–π —Ä–∏—Ç–µ–π–ª: X5, ¬´–ú–∞–≥–Ω–∏—Ç¬ª, ¬´–õ–µ–Ω—Ç–∞¬ª –∏ ...   MGNT  \n",
            "1    ‚úîÔ∏è –ú–∞–≥–Ω–∏—Ç ‚Äî —Å–¥–µ–ª–∫–∞ –∑–∞–∫—Ä—ã—Ç–∞.–°–µ–≥–æ–¥–Ω—è –±—ã–ª–∞ –∑–∞–∫—Ä—ã—Ç...   MGNT  \n",
            "2    ‚úîÔ∏è –ú–∞–≥–Ω–∏—Ç ‚Äî —Å–¥–µ–ª–∫–∞ –∑–∞–∫—Ä—ã—Ç–∞.–°–µ–≥–æ–¥–Ω—è –±—ã–ª–∞ –∑–∞–∫—Ä—ã—Ç...   MGNT  \n",
            "3    ‚Äã‚Äã–ú–∞–≥–Ω–∏—Ç - —Ä–∞–∑–º–∞–≥–Ω–∏—Ç–∏–ª—Å—è–î–∏—Å–∫–ª–µ–π–º–µ—Ä:¬†–°—Ç–∞—Ç—å—è –≤—ã—à...   MGNT  \n",
            "4    –ü–æ –ø—Ä–∏–∫–æ–ª—É —ç—Ç–æ–≥–æ –∫—Ä–æ–º–µ –∞–∫—Ü–∏–π –∏ —Ñ—å—é—á–µ–π –≤ –õ–æ–Ω–≥, ...   MGNT  \n",
            "..                                                 ...    ...  \n",
            "370  Max, –ø–µ—Ä–µ–¥ —Ç–µ–º –∫–∞–∫ –≤ –ø–æ–¥–≤–∞–ª–µ –ø—Ä—è—Ç–∞—Ç—å—Å—è ‚Äî –Ω–µ –∑–∞...   MGNT  \n",
            "371  –ö–æ–Ω—Å—Ç–∞–Ω—Ç–∏–Ω –ö–æ–±–ª–æ–≤, –∏–¥–∏ —Ç—ã –≤ –∂–æ–ø—É, –ù–ê–¢–û –ø—Ä–æ–≤–æ–¥–∏...   MGNT  \n",
            "372  –ö–æ–Ω—Å—Ç–∞–Ω—Ç–∏–Ω –ö–æ–±–ª–æ–≤, –∏–¥–∏ —Ç—ã –≤ –∂–æ–ø—É, –ù–ê–¢–û –ø—Ä–æ–≤–æ–¥–∏...   MGNT  \n",
            "373  –ö–æ–Ω—Å—Ç–∞–Ω—Ç–∏–Ω –ö–æ–±–ª–æ–≤, –∏–¥–∏ —Ç—ã –≤ –∂–æ–ø—É, –ù–ê–¢–û –ø—Ä–æ–≤–æ–¥–∏...   MGNT  \n",
            "374  –ü–µ—Ä—Å–ø–µ–∫—Ç–∏–≤—ã —Ä–æ—Å—Å–∏–π—Å–∫–æ–π —ç–∫–æ–Ω–æ–º–∏–∫–∏ —É–ª—É—á—à–∞—é—Ç—Å—è –Ω–∞...   MGNT  \n",
            "\n",
            "[375 rows x 4 columns]\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}